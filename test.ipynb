{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_dataset/eda_train_20.csv'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output = None\n",
    "input = './training_dataset/train_20.csv'\n",
    "from os.path import dirname, basename, join\n",
    "output = join(dirname(input), 'eda_' + basename(input))\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eda import *\n",
    "#the output file\n",
    "output = None\n",
    "input = './training_dataset/train_20.csv'\n",
    "from os.path import dirname, basename, join\n",
    "output = join(dirname(input), 'eda_' + basename(input))\n",
    "\n",
    "#number of augmented sentences to generate per original sentence\n",
    "num_aug = 9 #default\n",
    "\n",
    "#how much to replace each word by synonyms\n",
    "alpha_sr = 0.1#default\n",
    "\n",
    "#how much to insert new words that are synonyms\n",
    "alpha_ri = 0.1#default\n",
    "\n",
    "#how much to swap words\n",
    "alpha_rs = 0.1#default\n",
    "\n",
    "#how much to delete words\n",
    "alpha_rd = 0.1#default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['score', 'text']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mgenerated augmented sentences with eda for \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m train_orig \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m to \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m output_file \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m with num_aug=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(num_aug))\n\u001b[1;32m     20\u001b[0m \u001b[39m#generate augmented sentences and output into a new file\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m gen_eda(\u001b[39minput\u001b[39;49m, output, alpha_sr\u001b[39m=\u001b[39;49malpha_sr, alpha_ri\u001b[39m=\u001b[39;49malpha_ri, alpha_rs\u001b[39m=\u001b[39;49malpha_rs, alpha_rd\u001b[39m=\u001b[39;49malpha_rd, num_aug\u001b[39m=\u001b[39;49mnum_aug)\n",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m, in \u001b[0;36mgen_eda\u001b[0;34m(train_orig, output_file, alpha_sr, alpha_ri, alpha_rs, alpha_rd, num_aug)\u001b[0m\n\u001b[1;32m      9\u001b[0m parts \u001b[39m=\u001b[39m line[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m label \u001b[39m=\u001b[39m parts[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m sentence \u001b[39m=\u001b[39m parts[\u001b[39m1\u001b[39;49m]\n\u001b[1;32m     12\u001b[0m aug_sentences \u001b[39m=\u001b[39m eda(sentence, alpha_sr\u001b[39m=\u001b[39malpha_sr, alpha_ri\u001b[39m=\u001b[39malpha_ri, alpha_rs\u001b[39m=\u001b[39malpha_rs, p_rd\u001b[39m=\u001b[39malpha_rd, num_aug\u001b[39m=\u001b[39mnum_aug)\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m aug_sentence \u001b[39min\u001b[39;00m aug_sentences:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#generate more data with standard augmentation\n",
    "def gen_eda(train_orig, output_file, alpha_sr, alpha_ri, alpha_rs, alpha_rd, num_aug=9):\n",
    "\n",
    "    writer = open(output_file, 'w')\n",
    "    lines = open(train_orig, 'r').readlines()\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        parts = line[:-1].split(',')\n",
    "        label = parts[0]\n",
    "        sentence = parts[1]\n",
    "        aug_sentences = eda(sentence, alpha_sr=alpha_sr, alpha_ri=alpha_ri, alpha_rs=alpha_rs, p_rd=alpha_rd, num_aug=num_aug)\n",
    "        for aug_sentence in aug_sentences:\n",
    "            writer.write(label + \"\\t\" + aug_sentence + '\\n')\n",
    "\n",
    "    writer.close()\n",
    "    print(\"generated augmented sentences with eda for \" + train_orig + \" to \" + output_file + \" with num_aug=\" + str(num_aug))\n",
    "\n",
    "\n",
    "#generate augmented sentences and output into a new file\n",
    "gen_eda(input, output, alpha_sr=alpha_sr, alpha_ri=alpha_ri, alpha_rs=alpha_rs, alpha_rd=alpha_rd, num_aug=num_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
